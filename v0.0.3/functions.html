<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Functions · Merlin.jl</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="index.html"><img class="logo" src="assets/logo.png" alt="Merlin.jl logo"/></a><h1>Merlin.jl</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">Home</a></li><li><a class="toctext" href="var.html">Var</a></li><li class="current"><a class="toctext" href="functions.html">Functions</a><ul class="internal"><li><a class="toctext" href="#Activation-1">Activation</a></li><li><a class="toctext" href="#Convolution-1">Convolution</a></li><li><a class="toctext" href="#Loss-1">Loss</a></li><li><a class="toctext" href="#Math-1">Math</a></li><li><a class="toctext" href="#Random-1">Random</a></li><li><a class="toctext" href="#Recurrent-1">Recurrent</a></li><li><a class="toctext" href="#Reduction-1">Reduction</a></li><li><a class="toctext" href="#Misc-1">Misc</a></li></ul></li><li><a class="toctext" href="graph.html">Graph</a></li><li><a class="toctext" href="initializers.html">Initializaters</a></li><li><a class="toctext" href="optimizers.html">Optimizers</a></li><li><a class="toctext" href="datasets.html">Datasets</a></li><li><a class="toctext" href="save_load.html">Save and Load</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="functions.html">Functions</a></li></ul><a class="edit-page" href="https://github.com/hshindo/Merlin.jl/blob/master/docs/src/functions.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Functions</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Functions-1" href="#Functions-1">Functions</a></h1><ul><li><a href="functions.html#Merlin.BiLSTM"><code>Merlin.BiLSTM</code></a></li><li><a href="functions.html#Merlin.Conv1D"><code>Merlin.Conv1D</code></a></li><li><a href="functions.html#Merlin.LSTM"><code>Merlin.LSTM</code></a></li><li><a href="functions.html#Merlin.Linear"><code>Merlin.Linear</code></a></li><li><a href="functions.html#Merlin.Swish"><code>Merlin.Swish</code></a></li><li><a href="functions.html#Base.:*"><code>Base.:*</code></a></li><li><a href="functions.html#Base.:+"><code>Base.:+</code></a></li><li><a href="functions.html#Base.:-"><code>Base.:-</code></a></li><li><a href="functions.html#Base.:/"><code>Base.:/</code></a></li><li><a href="functions.html#Base.:^"><code>Base.:^</code></a></li><li><a href="functions.html#Base.broadcast"><code>Base.broadcast</code></a></li><li><a href="functions.html#Base.getindex"><code>Base.getindex</code></a></li><li><a href="functions.html#Base.max"><code>Base.max</code></a></li><li><a href="functions.html#Base.reshape"><code>Base.reshape</code></a></li><li><a href="functions.html#Base.tanh-Tuple{Merlin.Var}"><code>Base.tanh</code></a></li><li><a href="functions.html#Base.transpose"><code>Base.transpose</code></a></li><li><a href="functions.html#Merlin.argmax"><code>Merlin.argmax</code></a></li><li><a href="functions.html#Merlin.concat"><code>Merlin.concat</code></a></li><li><a href="functions.html#Merlin.crelu-Tuple{Merlin.Var}"><code>Merlin.crelu</code></a></li><li><a href="functions.html#Merlin.crossentropy"><code>Merlin.crossentropy</code></a></li><li><a href="functions.html#Merlin.dropout"><code>Merlin.dropout</code></a></li><li><a href="functions.html#Merlin.elu-Tuple{Merlin.Var}"><code>Merlin.elu</code></a></li><li><a href="functions.html#Merlin.l2"><code>Merlin.l2</code></a></li><li><a href="functions.html#Merlin.leaky_relu"><code>Merlin.leaky_relu</code></a></li><li><a href="functions.html#Merlin.logsoftmax"><code>Merlin.logsoftmax</code></a></li><li><a href="functions.html#Merlin.max_batch"><code>Merlin.max_batch</code></a></li><li><a href="functions.html#Merlin.mse"><code>Merlin.mse</code></a></li><li><a href="functions.html#Merlin.relu-Tuple{Merlin.Var}"><code>Merlin.relu</code></a></li><li><a href="functions.html#Merlin.selu-Tuple{Merlin.Var}"><code>Merlin.selu</code></a></li><li><a href="functions.html#Merlin.sigmoid-Tuple{Merlin.Var}"><code>Merlin.sigmoid</code></a></li><li><a href="functions.html#Merlin.softmax"><code>Merlin.softmax</code></a></li><li><a href="functions.html#Merlin.softmax_crossentropy"><code>Merlin.softmax_crossentropy</code></a></li></ul><h2><a class="nav-anchor" id="Activation-1" href="#Activation-1">Activation</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.crelu-Tuple{Merlin.Var}" href="#Merlin.crelu-Tuple{Merlin.Var}"><code>Merlin.crelu</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">crelu(x::Var)</code></pre><p>Concatenated Rectified Linear Unit. The output is twice the size of the input.</p><div>\[f(x) = (\max(0,x), \max(0,-x))\]</div><p><strong>References</strong></p><ul><li><p>Shang et al., <a href="https://arxiv.org/abs/1603.05201">&quot;Understanding and Improving Convolutional Neural Networks via Concatenated Rectified Linear Units&quot;</a>, arXiv 2016.</p></li></ul></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L4">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.elu-Tuple{Merlin.Var}" href="#Merlin.elu-Tuple{Merlin.Var}"><code>Merlin.elu</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">elu(x::Var)</code></pre><p>Exponential Linear Unit.</p><p><strong>References</strong></p><ul><li><p>Clevert et al., <a href="https://arxiv.org/abs/1511.07289">&quot;Fast and Accurate Deep Network Learning by Exponential Linear Units (ELUs)&quot;</a>, arXiv 2015.</p></li></ul><div>\[f(x) =
\begin{cases}
x &amp; x &gt; 0 \\
\alpha (e^{x}-1) &amp; x\leq0
\end{cases}\]</div><p>where <span>$\alpha=1$</span>.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L41">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.leaky_relu" href="#Merlin.leaky_relu"><code>Merlin.leaky_relu</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">leaky_relu(x::Var, alpha::Float64=0.2)</code></pre><p>Leaky Rectified Linear Unit.</p><div>\[f(x) =
\begin{cases}
x &amp; x &gt; 0 \\
\alpha x &amp; x \leq 0
\end{cases}\]</div><p><strong>References</strong></p><ul><li><p>Maas et al., <a href="http://web.stanford.edu/~awni/papers/relu_hybrid_icml2013_final.pdf">&quot;Rectifier Nonlinearities Improve Neural Network Acoustic Models&quot;</a>, ICML 2013.</p></li></ul></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L73">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.relu-Tuple{Merlin.Var}" href="#Merlin.relu-Tuple{Merlin.Var}"><code>Merlin.relu</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">relu(x::Var)</code></pre><p>Rectified Linear Unit.</p><div>\[f(x) = \max(0, x)\]</div></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L103">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.selu-Tuple{Merlin.Var}" href="#Merlin.selu-Tuple{Merlin.Var}"><code>Merlin.selu</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">selu(x::Var)</code></pre><p>Scaled Exponential Linear Unit.</p><div>\[f(x) = \lambda
\begin{cases}
x &amp; x &gt; 0 \\
\alpha e^{x}-\alpha &amp; x\leq0
\end{cases}\]</div><p>where <span>$\lambda=1.0507$</span> and <span>$\alpha=1.6733$</span>.</p><p><strong>References</strong></p><p>Klambauer et al., <a href="https://arxiv.org/abs/1706.02515">&quot;Self-Normalizing Neural Networks&quot;</a>, NIPS 2017.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L126">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.sigmoid-Tuple{Merlin.Var}" href="#Merlin.sigmoid-Tuple{Merlin.Var}"><code>Merlin.sigmoid</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">sigmoid(x)</code></pre><p>Sigmoid logistic function.</p><div>\[f(x) = (1 + \exp(-x))^{-1}\]</div></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L159">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.Swish" href="#Merlin.Swish"><code>Merlin.Swish</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">Swish</code></pre><p>Swish activation function.</p><div>\[f(x) = x \cdot \sigma (\beta x)\]</div><p>where <span>$\beta$</span> is a leanable parameter.</p><p><strong>References</strong></p><ul><li><p>Ramachandran et al. <a href="https://arxiv.org/abs/1710.05941">&quot;Searching for Activation Functions&quot;</a>, arXiv 2017.</p></li></ul></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L182">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.tanh-Tuple{Merlin.Var}" href="#Base.tanh-Tuple{Merlin.Var}"><code>Base.tanh</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">tanh(x::Var)</code></pre><p>Hyperbolic tangent function.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/activation.jl#L224">source</a></section><h2><a class="nav-anchor" id="Convolution-1" href="#Convolution-1">Convolution</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.Conv1D" href="#Merlin.Conv1D"><code>Merlin.Conv1D</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">Conv1D(T, ksize, insize, outsize, pad, stride, [dilation=1, init_W=Xavier(), init_b=Fill(0)])</code></pre><p>1-dimensional convolution function.</p><pre><code class="language-julia">T = Float32
x = Var(rand(T,10,5))
f = Conv1D(T, 5, 10, 3, 2, 1)
y = f(x)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/conv.jl#L3">source</a></section><h2><a class="nav-anchor" id="Loss-1" href="#Loss-1">Loss</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.l2" href="#Merlin.l2"><code>Merlin.l2</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">l2(x::Var, lambda::Float64)</code></pre><p>L2 regularization.</p><div>\[y = \frac{\lambda}{2}\left\Vert \mathbf{x} \right\Vert ^{2}\]</div><pre><code class="language-julia">x = Var(rand(Float32,10,5))
y = l2(x, 0.01)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/loss.jl#L68">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.crossentropy" href="#Merlin.crossentropy"><code>Merlin.crossentropy</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">crossentropy(p, q)</code></pre><p>Cross-entropy function between p and q.</p><div>\[f(x) = -\sum_{x} p(x) \log q(x)\]</div><ul><li><p>p::Var: <code>Var</code> of Vector{Int} or Matrix{Float}. If p is <code>Vector{Int}</code> and p[i] == 0, returns 0.</p></li><li><p>q::Var: <code>Var</code> of Matrix{Float}</p></li></ul><pre><code class="language-julia">p = Var(rand(0:10,5))
q = softmax(Var(rand(Float32,10,5)))
y = crossentropy(p, q)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/loss.jl#L3">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.mse" href="#Merlin.mse"><code>Merlin.mse</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">mse(x1, x2)</code></pre><p>Mean Squared Error function between <code>x1</code> and <code>x2</code>. The mean is calculated over the minibatch. Note that the error is not scaled by 1/2.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/loss.jl#L99">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.softmax_crossentropy" href="#Merlin.softmax_crossentropy"><code>Merlin.softmax_crossentropy</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">softmax_crossentropy(p, x)</code></pre><p>Cross-entropy function between p and <span>$softmax(x)$</span>.</p><div>\[f(x) = -\sum_{x} p(x) \log q(x)\]</div><p>where <span>$q = softmax(x)$</span></p><ul><li><p>p: Var of Vector{Int} or Matrix{Float}</p></li><li><p>q: Var of Matrix{Float}</p></li></ul><pre><code class="language-julia">p = Var(rand(0:10,5))
q = Var(rand(Float32,10,5))
y = softmax_crossentropy(p, x)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/loss.jl#L142">source</a></section><h2><a class="nav-anchor" id="Math-1" href="#Math-1">Math</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.broadcast" href="#Base.broadcast"><code>Base.broadcast</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">.+(x1::Var, x2::Var)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L129">source</a><div><pre><code class="language-none">.-(x1::Var, x2::Var)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L148">source</a><div><pre><code class="language-none">\.\*(x1::Var, x2::Var)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L167">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:+" href="#Base.:+"><code>Base.:+</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">+(x1::Var, x2::Var)
+(a::Number, x::Var)
+(x::Var, a::Number)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L91">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:-" href="#Base.:-"><code>Base.:-</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">-(x1, x2)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L107">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:*" href="#Base.:*"><code>Base.:*</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">\*(A::Var, B::Var)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L220">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:/" href="#Base.:/"><code>Base.:/</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">/(x1::Var, a)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L232">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.:^" href="#Base.:^"><code>Base.:^</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">^(x::Var, a::Number)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L249">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.transpose" href="#Base.transpose"><code>Base.transpose</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">transpose(x)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/math.jl#L66">source</a></section><h2><a class="nav-anchor" id="Random-1" href="#Random-1">Random</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.dropout" href="#Merlin.dropout"><code>Merlin.dropout</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">dropout(x::Var, rate::Float64, train::Bool)</code></pre><p>If <code>train</code> is true, drops elements randomly with probability <span>$rate$</span> and scales the other elements by factor <span>$1 / (1 - rate)$</span>. Otherwise, it just returns <code>x</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/dropout.jl#L3">source</a></section><h2><a class="nav-anchor" id="Recurrent-1" href="#Recurrent-1">Recurrent</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.BiLSTM" href="#Merlin.BiLSTM"><code>Merlin.BiLSTM</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">BiLSTM(::Type{T}, insize::Int, outsize::Int, [init_W=Uniform(0.001), init_U=Orthogonal()])</code></pre><p>Bi-directional Long Short-Term Memory network. See <code>LSTM</code> for more details.</p></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/recurrent.jl#L115">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.LSTM" href="#Merlin.LSTM"><code>Merlin.LSTM</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">LSTM(::Type{T}, insize::Int, outsize::Int, [init_W=Uniform(0.001), init_U=Orthogonal()])</code></pre><p>Long Short-Term Memory network.</p><div>\[\begin{align*}
\mathbf{f}_{t} &amp; =\sigma_{g}(W_{f}\mathbf{x}_{t}+U_{f}\mathbf{h}_{t-1}+\mathbf{b}_{f})\\
\mathbf{i}_{t} &amp; =\sigma_{g}(W_{i}\mathbf{x}_{t}+U_{i}\mathbf{h}_{t-1}+\mathbf{b}_{i})\\
\mathbf{o}_{t} &amp; =\sigma_{g}(W_{o}\mathbf{x}_{t}+U_{o}\mathbf{h}_{t-1}+\mathbf{b}_{o})\\
\mathbf{c}_{t} &amp; =\mathbf{f}_{t}\odot\mathbf{c}_{t-1}+\mathbf{i}_{t}\odot\sigma_{c}(W_{c}\mathbf{x}_{t}+U_{c}\mathbf{h}_{t-1}+\mathbf{b}_{c})\\
\mathbf{h}_{t} &amp; =\mathbf{o}_{t}\odot\sigma_{h}(\mathbf{c}_{t})
\end{align*}\]</div><ul><li><p><span>$x_t \in R^{d}$</span>: input vector to the LSTM block</p></li><li><p><span>$f_t \in R^{h}$</span>: forget gate&#39;s activation vector</p></li><li><p><span>$i_t \in R^{h}$</span>: input gate&#39;s activation vector</p></li><li><p><span>$o_t \in R^{h}$</span>: output gate&#39;s activation vector</p></li><li><p><span>$h_t \in R^{h}$</span>: output vector of the LSTM block</p></li><li><p><span>$c_t \in R^{h}$</span>: cell state vector</p></li><li><p><span>$W \in R^{h \times d}$</span>, <span>$U \in R^{h \times h}$</span> and <span>$b \in R^{h}$</span>: weight matrices and bias vectors</p></li><li><p><span>$\sigma_g$</span>: sigmoid function</p></li><li><p><span>$\sigma_c$</span>: hyperbolic tangent function</p></li><li><p><span>$\sigma_h$</span>: hyperbolic tangent function</p></li></ul><p><strong>👉 Example</strong></p><pre><code class="language-julia">T = Float32
x = Var(rand(T,100,10))
f = LSTM(T, 100, 100)
h = f(x)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/recurrent.jl#L42">source</a></section><h2><a class="nav-anchor" id="Reduction-1" href="#Reduction-1">Reduction</a></h2><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Base.max" href="#Base.max"><code>Base.max</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">max(x::Var, dim::Int)</code></pre><p>Returns the maximum value over the given dimension.</p><p><strong>👉 Example</strong></p><pre><code class="language-julia">x = Var(rand(Float32,10,5))
y = max(x, 1)</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/reduce.jl#L4">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="Merlin.max_batch" href="#Merlin.max_batch"><code>Merlin.max_batch</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">max_batch(x::Var, dims::Vector{Int})</code></pre></div><a class="source-link" target="_blank" href="https://github.com/hshindo/Merlin.jl/blob/ce29ef184779873c3ceba6688710536aa2f3caf0/src/functions/reduce.jl#L31">source</a></section><h2><a class="nav-anchor" id="Misc-1" href="#Misc-1">Misc</a></h2><pre><code class="language-none">argmax
batchsort
concat
getindex
Linear
logsoftmax
lookup
reshape
softmax
standardize
window1d</code></pre><footer><hr/><a class="previous" href="var.html"><span class="direction">Previous</span><span class="title">Var</span></a><a class="next" href="graph.html"><span class="direction">Next</span><span class="title">Graph</span></a></footer></article></body></html>
