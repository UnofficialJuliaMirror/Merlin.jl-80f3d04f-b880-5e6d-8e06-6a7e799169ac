{
    "docs": [
        {
            "location": "/", 
            "text": "Merlin.jl\n\n\nMerlin.jl is a flexible neural network library in Julia language.\n\n\nInstall\n\n\njulia\n \nPkg\n.\nclone\n(\nhttps://github.com/hshindo/Merlin.jl.git\n)\n\n\n\n\n\n\nRequirements\n\n\n\n\ngcc\n\n\ncuDNN v4 (if you use CUDA GPU)", 
            "title": "Home"
        }, 
        {
            "location": "/#merlinjl", 
            "text": "Merlin.jl is a flexible neural network library in Julia language.", 
            "title": "Merlin.jl"
        }, 
        {
            "location": "/#install", 
            "text": "julia   Pkg . clone ( https://github.com/hshindo/Merlin.jl.git )", 
            "title": "Install"
        }, 
        {
            "location": "/#requirements", 
            "text": "gcc  cuDNN v4 (if you use CUDA GPU)", 
            "title": "Requirements"
        }, 
        {
            "location": "/overview/", 
            "text": "Overview\n\n\nBasic types:\n\n\n\n\nVar\n\n\nFunctor\n\n\nNode\n\n\n\n\nVar\n\n\nVar{T}\n is a type of variable.\n\n\nx\n \n=\n \nVar\n(\nFloat32\n,\n \n10\n,\n \n5\n)\n\n\n\n\n\n\nFunctor\n\n\nFunctor\n is an abstract type of functors.\nA functor has two functions: \nforward\n and \nbackward\n.\n\n\nx\n \n=\n \nVar\n(\nFloat32\n,\n \n10\n,\n \n5\n)\n\n\nf\n \n=\n \nReLU\n()\n\n\ny\n \n=\n \nforward\n!\n(\nf\n,\n \nx\n)\n\n\ny\n.\ngrad\n \n=\n \n...\n\n\nbackward\n!\n(\nf\n)\n\n\n\n\n\n\nNode\n\n\nNode\n is used for constructing a computation graph of functors.\n\n\nn\n \n=\n \nNode\n(\nf\n)", 
            "title": "Overview"
        }, 
        {
            "location": "/overview/#overview", 
            "text": "Basic types:   Var  Functor  Node", 
            "title": "Overview"
        }, 
        {
            "location": "/overview/#var", 
            "text": "Var{T}  is a type of variable.  x   =   Var ( Float32 ,   10 ,   5 )", 
            "title": "Var"
        }, 
        {
            "location": "/overview/#functor", 
            "text": "Functor  is an abstract type of functors.\nA functor has two functions:  forward  and  backward .  x   =   Var ( Float32 ,   10 ,   5 )  f   =   ReLU ()  y   =   forward ! ( f ,   x )  y . grad   =   ...  backward ! ( f )", 
            "title": "Functor"
        }, 
        {
            "location": "/overview/#node", 
            "text": "Node  is used for constructing a computation graph of functors.  n   =   Node ( f )", 
            "title": "Node"
        }, 
        {
            "location": "/functors/concat/", 
            "text": "Concat\n\n\nConcatenates n-d arrays along the specified dimension.\n\n\nParams\n\n\n\n\ndim::Int\ndimension\n\n\n\n\nInput\n\n\nn-d arrays. The number of dimensions of the input arrays must be the same.\n\n\nOutput\n\n\nconcatenated n-d array\n\n\nExample\n\n\nf\n \n=\n \nConcat\n(\n1\n)\n\n\nx\n \n=\n \nVar\n()\n\n\ny\n \n=\n \nf\n(\nx\n)", 
            "title": "Concat"
        }, 
        {
            "location": "/functors/crossentropy/", 
            "text": "CrossEntropy\n\n\nComputes cross-entropy between a true distribution math:$p$ and the specified distribution math:$q$, that is,\n$\\mathrm{H}(p,q)=-\\sum_{x}p(x)\\log q(x)$\n\n\nParams\n\n\n\n\np\n\n\n\n\nInput\n\n\n\n\nn-d array\n\n\n\n\nOutput\n\n\n\n\nn-d array\n\n\n\n\nExample", 
            "title": "CrossEntropy"
        }, 
        {
            "location": "/functors/linear/", 
            "text": "Linear\n\n\n$y = Wx + b$\n\n\nParams\n\n\n\n\nw\n\n\nb\n\n\n\n\nInput\n\n\nn-d array\n\n\nOutput\n\n\nn-d array\n\n\nExample\n\n\nf\n \n=\n \nLinear\n()\n\n\nx\n \n=\n \nVar\n()\n\n\ny\n \n=\n \nf\n(\nx\n)", 
            "title": "Linear"
        }, 
        {
            "location": "/functors/relu/", 
            "text": "ReLU\n\n\nReLU\n is a rectifier linear unit.\n\n\nParams\n\n\nInput\n\n\nn-d array\n\n\nOutput\n\n\nn-d array\n\n\nExample", 
            "title": "ReLU"
        }, 
        {
            "location": "/examples/pos-tagging/", 
            "text": "POS-Tagging\n\n\nIn this tutorial, we explain a pos-tagger based on neural network.\n\n\n[Santos] dosSantos and Zadrozny,\n  \nLearning Character-level Representations for Part-of-Speech Tagging\n,\n  In Proceedings of ICML, 2014.\n\n\nPreparing the Data\n\n\nCoNLL-format Penn Treebank\n\n\nDefining the Network Architecture\n\n\nThe neural pos-tagger consists of three types of layers:\n\n\nFirst, we define a Token type:\n\n\n  \ntype\n Token\n\n    \ndicts\n::\nTuple\n{\nDict\n,\n \nDict\n,\n \nDict\n}\n\n    \nwordid\n::\nInt\n\n    \ncharids\n::\nVector\n{\nInt\n}\n\n    \ncatid\n::\nInt\n\n  \nend\n\n\n\n\n\n\n  \nusing\n \nMerlin\n\n\n  \ntype\n LayerSet\n\n    \nwordembed\n::\nLookup\n\n    \ncharseq\n::\nSequence\n\n    \nwordseq\n::\nSequence\n\n  \nend\n\n\n\n\n\n\nThen we need to define a forward function:\n\n\n```julia\n  function forward(ls::LayerSet, data::Vector{Token})\n\n\nend\n```julia", 
            "title": "POS-Tagging"
        }, 
        {
            "location": "/examples/pos-tagging/#pos-tagging", 
            "text": "In this tutorial, we explain a pos-tagger based on neural network.  [Santos] dosSantos and Zadrozny,\n   Learning Character-level Representations for Part-of-Speech Tagging ,\n  In Proceedings of ICML, 2014.  Preparing the Data  CoNLL-format Penn Treebank  Defining the Network Architecture  The neural pos-tagger consists of three types of layers:  First, we define a Token type:     type  Token \n     dicts :: Tuple { Dict ,   Dict ,   Dict } \n     wordid :: Int \n     charids :: Vector { Int } \n     catid :: Int \n   end      using   Merlin \n\n   type  LayerSet \n     wordembed :: Lookup \n     charseq :: Sequence \n     wordseq :: Sequence \n   end   Then we need to define a forward function:  ```julia\n  function forward(ls::LayerSet, data::Vector{Token})  end\n```julia", 
            "title": "POS-Tagging"
        }
    ]
}