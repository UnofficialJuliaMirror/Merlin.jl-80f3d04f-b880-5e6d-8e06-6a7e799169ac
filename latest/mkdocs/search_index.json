{
    "docs": [
        {
            "location": "/", 
            "text": "Merlin.jl\n\n\nMerlin\n is a deep learning framework written in \nJulia\n. It aims to provide a fast, flexible and compact deep learning library for machine learning.\n\n\nSee README.md for basic usage.", 
            "title": "Home"
        }, 
        {
            "location": "/#merlinjl", 
            "text": "Merlin  is a deep learning framework written in  Julia . It aims to provide a fast, flexible and compact deep learning library for machine learning.  See README.md for basic usage.", 
            "title": "Merlin.jl"
        }, 
        {
            "location": "/overview/", 
            "text": "Overview\n\n\n\n\nWrap data with \nVar\n.\n\n\nApply functions to the variables.\n\n\n\n\nx\n \n=\n \nVar\n(\nrand\n(\nFloat32\n,\n10\n,\n5\n))\n\n\n\n\n\n\n\n\nForward and Backward Computation\n\n\n```@example\nusing Merlin #hide\nx = param(rand(Float32,10,5))\nf = Linear(Float32,10,7)\ny = f(x)\ngradient!(y)\n\n\na\n \nid=\nTraining-1\n/a\n\n\n## Training\n\n\nRather than manually call `gradient!`, Merlin provides `fit` function for training model.\n\n\n```julia\nusing Merlin\n\ndata_x = [Var(rand(Float32,10,5)) for i=1:100] # input data\ndata_y = [Var([1,2,3]) for i=1:100] # correct labels\n\nopt = SGD(0.0001)\nfor epoch = 1:10\n  println(\nepoch: $(epoch)\n)\n  loss = fit(f, crossentropy, opt, data_x, data_y)\n  println(\nloss: $(loss)\n)\nend\n\n\n\n\n\nwhere \nfit\n tales five arguments: \ndecode\n, \nloss function\n, \noptimizer\n.", 
            "title": "Overview"
        }, 
        {
            "location": "/overview/#overview", 
            "text": "Wrap data with  Var .  Apply functions to the variables.   x   =   Var ( rand ( Float32 , 10 , 5 ))", 
            "title": "Overview"
        }, 
        {
            "location": "/overview/#forward-and-backward-computation", 
            "text": "```@example\nusing Merlin #hide\nx = param(rand(Float32,10,5))\nf = Linear(Float32,10,7)\ny = f(x)\ngradient!(y)  a   id= Training-1 /a \n\n## Training\n\n\nRather than manually call `gradient!`, Merlin provides `fit` function for training model.\n\n\n```julia\nusing Merlin\n\ndata_x = [Var(rand(Float32,10,5)) for i=1:100] # input data\ndata_y = [Var([1,2,3]) for i=1:100] # correct labels\n\nopt = SGD(0.0001)\nfor epoch = 1:10\n  println( epoch: $(epoch) )\n  loss = fit(f, crossentropy, opt, data_x, data_y)\n  println( loss: $(loss) )\nend  where  fit  tales five arguments:  decode ,  loss function ,  optimizer .", 
            "title": "Forward and Backward Computation"
        }, 
        {
            "location": "/functions/", 
            "text": "Functions\n\n\n#\n\n\nMerlin.relu\n \n \nMethod\n.\n\n\nrelu(x::Var)\n\n\n\n\n\nRectifier liner unit.\n\n\n\ud83d\udc49 Example\n\n\nx\n \n=\n \nVar\n(\nrand\n(\nFloat32\n,\n10\n,\n5\n))\n\n\ny\n \n=\n \nrelu\n(\nx\n)\n\n\n\n\n\n\n#\n\n\nMerlin.sigmoid\n \n \nMethod\n.\n\n\nsigmoid(x::Var)\n\n\n\n\n\n#\n\n\nBase.tanh\n \n \nMethod\n.\n\n\ntanh(x::Var)\n\n\n\n\n\n#\n\n\nMerlin.concat\n \n \nMethod\n.\n\n\nconcat(dim::Int, xs::Var...)\nconcat(dim::Int, xs::Vector{Var})\n\n\n\n\n\nConcatenate arrays along the given dimension.\n\n\n\ud83d\udc49 Example\n\n\nx1\n \n=\n \nVar\n(\nrand\n(\nFloat32\n,\n7\n,\n5\n))\n\n\nx2\n \n=\n \nVar\n(\nrand\n(\nFloat32\n,\n10\n,\n5\n))\n\n\ny\n \n=\n \nconcat\n(\n1\n,\n \nx1\n,\n \nx2\n)\n\n\n\n\n\n\n#\n\n\nMerlin.crossentropy\n \n \nMethod\n.\n\n\ncrossentropy(p::Var, q::Var)\n\n\n\n\n\nCompute cross-entropy between two distributions $p$ and $q$, where $p$ is usually correct labels and $q$ is predicted values.\n\n\n$ f(p,q)=-\u2211\n{x} p\n \\log q_{x} $\n\n\nArguments\n\n\n\n\np: variable of \nVector{Int}\n or \nMatrix{Float}\n. p must be normalized.\n\n\nq: variable of \nMatrix{Float}\n.\n\n\n\n\n\ud83d\udc49 Example\n\n\np\n \n=\n \nVar\n([\n1\n:\n5\n;])\n\n\nq\n \n=\n \nVar\n(\nrand\n(\nFloat32\n,\n10\n,\n5\n))\n\n\ny\n \n=\n \ncrossentropy\n(\np\n,\n \nq\n)", 
            "title": "Functions"
        }, 
        {
            "location": "/functions/#functions", 
            "text": "#  Merlin.relu     Method .  relu(x::Var)  Rectifier liner unit.  \ud83d\udc49 Example  x   =   Var ( rand ( Float32 , 10 , 5 ))  y   =   relu ( x )   #  Merlin.sigmoid     Method .  sigmoid(x::Var)  #  Base.tanh     Method .  tanh(x::Var)  #  Merlin.concat     Method .  concat(dim::Int, xs::Var...)\nconcat(dim::Int, xs::Vector{Var})  Concatenate arrays along the given dimension.  \ud83d\udc49 Example  x1   =   Var ( rand ( Float32 , 7 , 5 ))  x2   =   Var ( rand ( Float32 , 10 , 5 ))  y   =   concat ( 1 ,   x1 ,   x2 )   #  Merlin.crossentropy     Method .  crossentropy(p::Var, q::Var)  Compute cross-entropy between two distributions $p$ and $q$, where $p$ is usually correct labels and $q$ is predicted values.  $ f(p,q)=-\u2211 {x} p  \\log q_{x} $  Arguments   p: variable of  Vector{Int}  or  Matrix{Float} . p must be normalized.  q: variable of  Matrix{Float} .   \ud83d\udc49 Example  p   =   Var ([ 1 : 5 ;])  q   =   Var ( rand ( Float32 , 10 , 5 ))  y   =   crossentropy ( p ,   q )", 
            "title": "Functions"
        }, 
        {
            "location": "/graph/", 
            "text": "", 
            "title": "Graph"
        }, 
        {
            "location": "/optimizers/", 
            "text": "Optimizers\n\n\n#\n\n\nMerlin.SGD\n \n \nType\n.\n\n\nStochastic Gradient Descent.", 
            "title": "Optimizers"
        }, 
        {
            "location": "/optimizers/#optimizers", 
            "text": "#  Merlin.SGD     Type .  Stochastic Gradient Descent.", 
            "title": "Optimizers"
        }, 
        {
            "location": "/gpu/", 
            "text": "", 
            "title": "GPU"
        }, 
        {
            "location": "/caffe/", 
            "text": "Interop with Caffe\n\n\nTo be written...\n\n\n\n\nVGG_ILSVR_19_layers.caffemodel\n\n\n\n\ngit clone caffe\n\n\n\n\n\n\u2013", 
            "title": "Caffe"
        }, 
        {
            "location": "/caffe/#interop-with-caffe", 
            "text": "To be written...   VGG_ILSVR_19_layers.caffemodel   git clone caffe  \u2013", 
            "title": "Interop with Caffe"
        }
    ]
}